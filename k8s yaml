Pod
 └── spec
     └── containers
         ├── name
         ├── image
         ├── ports

Anything that runs a container starts with a Pod.

Service
 └── spec
     ├── type
     ├── selector
     └── ports
         ├── port
         └── targetPort

Pods change, Services don’t.
Service selects Pods using labels, not names.

Deployment
 └── spec
     ├── replicas
     ├── selector
     │    └── matchLabels
     └── template
          ├── metadata
          │    └── labels
          └── spec
               └── containers
Anything related to Pods goes inside template.
selector.matchLabels MUST match template.metadata.labels.
You talk to Deployments, not Pods.

Deployment
 └── template
      └── spec
           └── containers
                ├── image
                ├── ports
                └── env
This rule saves you from 70% of YAML errors.

***comand to generate secret with encoding as encoding needs more efforts and additional steps while setting it up using yaml

kubectl create secret generic db-secret \
  --from-literal=DB_USER=admin \
  --from-literal=DB_PASSWORD=password \
  --dry-run=client -o yaml


******************************Formula to remember the what goes where**************
template.metadata   → labels, annotations
template.spec       → pod-level (volumes, restartPolicy, nodeSelector, affinity)
containers[]        → runtime (image, ports, env, command, args, resources, volumeMounts)


**********************master yaml template ********************************

Deployment
├── apiVersion            ← ALWAYS present (AKM)
├── kind                  ← ALWAYS present
├── metadata              ← Resource identity
│   ├── name
│   ├── labels
│   └── annotations
│
└── spec                  ← Deployment spec (NOT pod yet)
    ├── replicas
    ├── selector
    │   └── matchLabels
    │
    └── template           ← Pod template (this creates Pods)
        ├── metadata       ← Pod identity
        │   └── labels     ← MUST match selector
        │
        └── spec           ← Pod spec (THIS is the real runtime spec)
            ├── volumes
            ├── restartPolicy
            ├── nodeSelector / affinity / tolerations
            │
            └── containers
                ├── name
                ├── image
                ├── ports
                ├── command / args
                ├── env
                ├── envFrom
                ├── resources
                └── volumeMounts



**********************service ***************************
Service
 ├── apiVersion
 │     └── v1
 ├── kind
 │     └── Service
 ├── metadata
 │     ├── name           # Service name
 │     ├── namespace      # Optional; defaults to 'default'
 │     └── labels         # Metadata labels (for identification, Helm, monitoring)
 ├── spec
 │     ├── type           # ClusterIP | NodePort | LoadBalancer
 │     │     └── Note: ClusterIP default; NodePort requires optional nodePort; LoadBalancer works with cloud
 │     ├── selector       # MUST match Pod labels exactly (traffic goes only to Pods matching ALL labels)
 │     │     ├── label1
 │     │     ├── label2
 │     │     └── ...
 │     │     └── Note: Selector labels do NOT need to match Service metadata labels
 │     └── ports
 │           ├── - name       # Optional; required if multiple ports
 │           ├──   protocol   # TCP/UDP (HTTP/HTTPS is handled at app level)
 │           ├──   port       # Service port exposed internally
 │           └──   targetPort # Container port in Pods
 │
 └── Notes/Interview tips:
       - Service labels (metadata.labels) are independent of selector; used for organization or queries
       - Selector labels define which Pods get traffic
       - Service can select multiple Pods with multiple labels
       - Multi-port Service allows exposing multiple application endpoints
       - type: NodePort or LoadBalancer only changes how traffic enters the cluster; other spec remains same
       - NodePort optional: nodePort (range 30000-32767)
       - LoadBalancer optional: external cloud IP created
